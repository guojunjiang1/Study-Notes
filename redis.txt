为什么使用redis？在项目中，很多场景的并发量很大，如秒杀之类，若不适用redis缓存直接让其访问数据库，那么会对数据库造成很大的压力从而导致数据库崩了，因此引入redis做分布式缓存
redis是非关系型数据库 CP，命令不区分大小写，key区分大小写
redis新加的命令：help @命令（String，List...）来查看这些命令的使用方法
redis的五种数据结构：
一：String类型 keyValue都是String （可以用作缓存，可以通过String的incr原子递增的方式来记录访问量，incr num（让key为num的value递增））
二：List类型 Value可存放多个值，有序且重复（可以通过lpush，rpop实现队列 也可以通过range范围查询来实现分页功能，用户最近视频观看记录）
三：Set类型 无序但不可重复（因为可以自动去重因此可以实现并集交集差集，可以实现好友去重，可以实现抽奖活动，去重保证每个人参加一次，可以实现朋友圈点赞）
四：Zset类型 对应的每个set元素可添加一个分数（可以实现排行榜）
zset的底层是用跳表（一个多层的有序链表，一种基于概率统计的插入算法）实现
五：Hash类型 value就是一个map类型（购物车）

六：bitmap：底层初始所有的数据都是0，它是以0,1的方式存储数据的
可以实现分布式布隆过滤器。
可以实现用户签到的功能（setbig 20201016(key)  5(用户Id)  1）每天用户签到后，设置日期：用户Id对应的下标设为1，然后前一天和后一天的进行按位与运算，得到的结果为连续两天都签到的人。
可以记录每天日活用户量：每个用户登录后执行 setbig key 用户ID 1,最后用BIGCOUNT key 0 -1 来统计值为1的总数得到日活用户量

HyperLogLog GEO Stream

redis的持久化技术：因为redis是在内存中工作，一旦关闭所有数据就消失了，因此需要使用一种持久化的技术，将redis的数据保存起来
RDB和AOF
RDB：SAVE命令持久化会阻塞当前的redis（RDB主要负责全量持久化），显然调用SAVE命令进行持久化是不合适的
          BGSAVE命令持久化时会fork一个一模一样的子进程进行持久化，不会对用户线程造成影响
          RDB相比于AOP速度更快但其可能会造成数据的丢失（Redis意外down掉的话，会丢失最后一次快照的修改）
AOF：可以支持实时的持久化，AOF文件通常比RDB大恢复起来慢（AOF主要负责增量持久化）,但其可以保证数据的完整性

RDB和AOF的选择问题：
当对数据很敏感且不允许分钟内的数据丢失则使用AOF，若数据量较大且追求恢复速度使用RDB，RDB非常适合灾难恢复，不过还是建议两个持久化策略一起使用。
开机启动时，先查看是否开启了AOF，如果开启则加载AOF的Appendonly.aof，没开启则加载RDB的dump.rdb
对于主从同步来说，从库启动后先执行RDB实现全量同步，再执行AOF进行实时持久化
RDB是以二进制形式保存的，AOF则是追加每次写入的命令。

redis的事务：redis也支持事务，只不过他的事务和mysql的不同，他的是谁成功就是成功，失败就是失败，即使失败了也不会让其他成功的回滚

redis的雪崩问题：当redis当中很多字段都同时失效时，大量的请求直接打进了mysql当中，造成了redis的雪崩。 
解决方法：①可以设置他们的失效期均匀分布②在程序中设置限流降级操作③如果是因为redis宕机问题，则可以设置redis集群保证高可用④数据预热，在活动开始前提前将数据存入redis当中。

redis的缓存穿透：用户恶意访问mysql中不存在的数据，故redis也没有因此会造成大量的请求打到mysql中。
解决方式：
一：redis添加空数据：在数据库中查不到数据时，自定义一个类存到redis中，每次查询redis后，instanceof 自定义的class，如果为True则说明是空数据，直接返回查不到，不再去查询mysql
二：访问mysql前添加布隆过滤器，现将mysql中的数据id存储到布隆过滤器，布隆过滤器中以0，1的方式存放mysql中的数据，当判断数据是否存在布隆过滤器时，它会对给定的元素进行Hash计算
如果结果都为1则数据在布隆过滤器中，如果有一个为0则数据不存在布隆过滤器中，直接返回不再让它执行后面的代码
（布隆过滤器也是有误差的，布隆过滤器中存在的数据mysql不一定存在，布隆过滤器中不存在的数据mysql一定不存在）
框架的布隆过滤器只适合于单机版，我们可以使用redis的bitmap（bitmap底层存储的也是0,1数据）实现分布式布隆过滤器

redis的缓存击穿：当多个用户访问某一个热点数据，该数据在redis中突然失效，此时大量的请求又会打到mysql当中。
解决方法：一：提前加载热key数据到内存中，如果redis数据过期，走内存查询
	 二：缓存失效，则添加锁只允许一个线程去访问mysql，访问完mysql将数据重新添加到缓存后释放锁，再让其他线程访问缓存
	 三：设置热点数据永不过期

redis的主从复制：复制一份一模一样的redis，实现读写分离高可用，主库负责写，从库负责读
原理：从库（slave）监听主库（master）：Slaveof  （主库的）ip 端口
          从库启动后连接到master后会发送一个psync命令，如果该从库是第一次连接主库，则master接到命令后会执行BGSAVE命令，启动后台的存盘进程，收集所有的修改命令，生成RDB快照，
          然后将RDB传送给从库，从库完成全量同步。之后新增到master的数据可以使用AOF增量同步到从库


从库突然断开连接，当从库恢复后，主库怎么把宕机这段时间的数据同步到从库？
可以将所有数据全量同步过去，但这样效率不高，所以我们可以在主库向从库同步数据时，同时写一份数据到主库的缓冲区当中，然后各个库设置一个复制偏移量（用来记录数据同步到哪儿），这样当从库重新连接
回来之后，可以根据复制偏移量到主库的缓冲区中去获取丢失的数据。
进阶：如果这时候新增了一个从库，它内部也有复制偏移量，主库就根据它的数据偏移量将不正确的数据发送过去了，此时就会产生出问题。
          解决方法：我们可以每次在运行时都产生一个运行ID，在数据同步前比较一下运行ID。

redis的哨兵模式：当主库挂了之后，从库通过投票的方式选出一个从库来转为主库(最少要有3个哨兵实例)
配置方式：主库新建一个sentinel.conf文件，编写 sentinel monitor 自定义名 本机io 端口 x：x表示主机挂掉之后，从机的投票数的满足条件
哨兵的作用：①：集群监控：负责监控Redis master和slave是否正常工作
	    ②：消息通知：当某个Redis实例发生故障时，发送消息作为报警通知给管理员
	    ③：故障转移：如果master节点挂了，那么在slave节点中自动选取一个作为新的master
	    ④：配置中心：如果故障转移发生了，则会通知其他slave新的master地址

如何在redis中找出key是以某个固定前缀开头的数据？
可以采用keys指令来扫描指定前缀的key。
若当前redis正在线上使用，调用keys指令时，由于redis是单线程的故会阻塞一段时间直到keys指令执行完毕，这时可以使用scan命令，可无阻塞的进行扫描指定前缀的key，但scan执行时间比keys长。

redis为什么快？
因为他的操作是基于内存的
且采用了io多路复用技术
它是单线程避免了多线程环境下不必要的上下文切换（多线程下Cpu为每个线程分配一个时间片，时间片结束重新进入就绪状态，会让其他线程执行，其他线程执行完之后又会切换回回来）
也不必担心锁的问题，也不会出现死锁情况

为什么redis6.0之后又使用了多线程？
redis6.0之后使用了多线程，但是redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。
这样做的目的在于redis的性能瓶颈是网络io而非cpu，使用多线程可以提升IO读写的效率，从而提升redis的性能。

redis的线程模型：
redis所采用的线程模型是文件事件处理器，文件事件处理器是单线程的，所以redis也是单线程的，它采用io多路复用来同时监听多个Socket

io多路复用：redis当中利用了select poll epoll可以同时监听多个流的IO事件能力，在空闲时，他会把线程阻塞掉，当一个或多个流有IO事件发生时，就会从阻塞状态中唤醒，程序会轮询一次所有的流，按顺序处理
就绪的流，此时就可以避免大量的无用操作。
多路：多个网络连接 复用：复用同一线程 采用io多路复用可以让单个线程高效的处理多个连接请求

redis默认的内存大小：默认情况下是没有设置内存大小的，如果没设置redis内存就占总机的内存大小（总机4G，它也占4G）
		  可以在redis的配置文件中设置Memory大小

redis的过期淘汰策略:（存放的数据设置过期时间后如何在到达时间后移除数据）
当数据达到过期时间后，不会第一时间删除，它的过期策略是惰性删除（取数据时，判断一下是否过期，过了就删除），定时删除（每隔一段时间，随机取一些数据判断是否过期，过期就删除）

redis的内存淘汰策略：（当内存满了，需要淘汰一些数据）
FIFO：淘汰最早添加进来的数据 LRU：淘汰最近最少使用的数据 LFU：淘汰最近使用频率最少的数据 random：随机淘汰
当内存满了，再添加数据，redis会抛出oom异常

LRU的实现：
可以通过LinkedHashMap来实现，LinkedHashMap底层是一个数组+双向链表的结构，和HashMap存放元素的方式一样都是根据hash计算出索引，然后存放元素，发生hash冲突采用拉链法解决
唯一不同的是，它每个数组对应的链表之间都有相互的连接引用关系，eg：数组1的链表的下一个元素指向了数组2的链表。
一：基于LinkedHashMap
LinkedHashMap中提供了一个remove方法，这个方法就是用于删除最近最少使用的数据的（队头数据）
LinkedHashMap构造函数中可以指定元素排序的参数，当为true时它是按照访问时间排序的最近访问的放在队尾，当为false时它是按照存放顺序排序的最近插入的放在队尾
二：基于双端队列+hashMap
自定义结点：存放k，v，前指针+后指针
双端链表：可以看做是一个队列，这正好符合了LRU的思想，淘汰最近使用最少的数据，那么对于使用了的数据可以移动到队尾，队头的数据就是使用最少的数据
hashMap：它的泛型是<K，Node<K,V>>，通过hashMap来存放数据，因为它可以提供O(1)的查询效率以及自带了去重的功能
也就是说最终的LRU，存放的数据会存放在两个地方，一个是双端队列中，一个是hashMap中	

redis的事务：
通过MULTI(begin),EXEC(commit),DISCARD(放弃这个事务),WATCH(监控乐观锁)这四个命令来完成
MULTI:就相当于开启事务的操作
EXEC:相当于提交操作
DISCARD：放弃当前这个事务
WATCH：在事务开启后，监控某一个KEY，如果这个KEY在事务提交前，其他的客户端也对这个KEY做了修改操作，那么在事务提交的时候这个KEY就提交失败了（相当于乐观锁）

Redis事务的作用：将一串操作放入同一事务中保证它们的原子性。
Redis事务是不回滚的，对于事务中的命令当有命令发生错误也不会影响其他的命令。     

为什么使用redis不使用Memcache
一：因为MC的Key不能超过250字节Value不能超过1M字节
二：key的最大失效时间为30天
三：MC不支持持久化和主从同步
四：redis支持更多的数据结构（MC只支持String类型），redis采用单线程模式处理请求（MC是多线程），因此可以采用非阻塞的异步处理机制，单线程还可以避免线程上下文切换浪费的时间

如何保证数据库和redis的数据一致性：
（如果先删缓存，再更新数据库，则有可能出现，更新数据库前，有个读请求来了，查询缓存MISS，又去查询数据库，数据库的旧数据再写入Redis当中，最后Redis存放的是旧数据，数据库存放的是新数据）
（如果先更新数据库，再删缓存，有可能出现更新数据库成功，删除缓存失败，数据不一致）
①：采用延迟双删：
一：删除缓存中的数据
二：更新数据库中的数据
三：根据业务情况，睡眠一定时间（害怕出现：读取操作在更新数据库前，当执行完第四步，才将读取的数据存入到redis，这时就造成了数据不一致，因此需要等待读取所需时间后再删除）
四：再删除缓存中的数据（若在更新前，又进行读取，读取到的是更新前的脏数据，确保缓存中存放的不是之前的数据）
②：采用消息队列：
先更新数据库再删除redis
如果redis删除失败：
一：在catch中将删除失败的key发送到消息队列
二：自己接受消息
三：获取要删除的key后，进行重试删除操作直至删除成功
③：设置缓存的过期时间：这样无论如何最终过期后都会去mysql中读取最新的数据
④：采用RocketMQ的事务消息来解决

如何保证Redis的并发竞争key问题：
所谓Redis的并发竞争key问题，就是多个服务同时对一个key进行操作，但最终执行的顺序和我们预期的顺序不同,这就导致了不同的结果
解决方法：通过分布式锁可以解决这个问题，也可以把这些操作按顺序放到mq里，通过mq顺序执行的机制，消息接收方进行执行

使用Hash存储商品数据，当数据量很大时，如何进行优化？
Hash的结构是：key filed value，当存储商品时，一般key设置为product，由于数据量很大，对同一key进行操作会有阻塞的情况。
分段存储：我们可以存储数据时，通过商品Id%1000获取值0-999之间，然后存储时就可以：key：（product：10），filed：具体id，value：商品信息，这样就可以保证每个key下的商品数据量都不大

redis是单线程的，那我们现在的服务器都是多核的，是不是会有性能的浪费？
虽然他是单线程的，但我们可以在单机开多个Redis实例
如果单机还有瓶颈，那么也可以在多机下开启redis集群（cluster）

数据同步的时候断网了或者服务器挂了怎么办？
在网络恢复或者服务器恢复后，会自动把缺少的数据补上。

redis的常见命令：
String：set k v，get k
hash：hset k filed v，hget k filed
list：lpush k v，rpush k v，lpop k，rpop k，
set：sadd k v，spop k
zset：zadd k score v

redis的底层结构：
String：是动态的，相对于c语言的String而言它可以常数时间获取长度，能自动扩容并且惰性删除和二进制安全。
Zset：底层是跳表，一个多层的有序链表
hash：有两个表，平时用一个，当扩容时，添加或删除一个元素时，移到新的表，直到扩容完毕，查找数据时先到老的表找，再去新的表找
list：底层是个链表
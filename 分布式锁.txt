基于redis的分布式锁：（redisson框架快速实现）
通过redis中的setnx来实现
一：当程序发生异常无法释放锁：try，finally方式释放锁
二：当程序宕机无法释放锁：设置锁的存活时间
三：当出现A释放B的锁：为锁设置一个Value，存入ThreadLocal中，在释放锁之前，判断锁的Value是否和自己的ThreadLocal中的相同
四：若业务执行时间大于锁的存活时间怎么办，可以启动一个线程，定期给锁增加存活时间直至锁释放
五：如何优化：可以对redis进行分段加锁的思想，将一个库存库，分成多个库存库，将一个库的串行加锁变成多个库的并行加锁
如果请求到达A库存库发现库存不足，那么可以继续对B库存库尝试加锁，然后同时从AB扣减库存即可
（eg：A库存有10个商品，B库存有20个商品，请求来了要买25个商品，发现A库存不足，则尝试对B库存加锁，加锁成功后在A库存扣减10个商品，B库存扣减15个商品即可）
六：若redis主库宕机，假设有主从两个库，向主库添加锁成功，数据还没来得及同步给从库，此时主库宕机了，从库成了新的主库，一个线程来了向新主库中添加锁，由于锁的数据没同步过来，那么就添加成功了，
此时其实就出现了两个线程同时添加锁成功的问题了。
解决方法：可以设置延迟重启，等宕机的库中的锁释放后（业务代码执行完）再让从库变成新的主库。
七：删除锁时的操作不是原子性的（先判断锁是否存在且是自己的value，然后再删除），这样可能会出现问题，比如当判断完是自己的锁在要删除前，锁自动过期了，然后其他线程刚创建了锁，这时删除的
就成了别人的锁了。
解决方法：使用lua脚本让这个操作变成原子性的操作（通过Jedis来操作redis）
	 使用redis的事务，Watch监听锁的KEY，然后开启一个事务，执行删除操作，再提交事务，如果在提交事务时锁被其他线程修改过，那么提交是不成功的因为我们监听了这把锁
	 （对于被监听的KEY，在提交前如果被修改过，提交是不成功的）（只要锁自动过期其他线程获取到这把锁，那么就不会出现误删除锁的情况）（如果锁一直没被修改过，那么就会正确释放掉锁）												               					

redis集群下的加锁：如果在redis集群下加单一的锁很可能会由于数据延时的问题，导致出现两个线程都加锁成功，所以我们需要采用宏锁的方式来加锁，所谓宏锁即执行多个加锁操作，当有一半以上的加锁操作
成功，才算是加锁成功，redisson中有具体的实现

基于zookeeper的分布式锁：（curator（q瑞ta）框架快速实现）
通过zookeeper的临时节点来实现（carete -e /exclusive/lock）
程序流程：
尝试创建临时节点lock，如果创建失败说明其他线程已创建了，那么就进入监听/等待状态(get -w /exclusive/lock等待临时节点lock的删除)
		    创建成功，则就意味着成功获取到锁了，完成业务的处理，释放锁（也就是删除掉临时节点lock）

优化：
羊群效应：上面这种方法所添加的锁是非公平锁，每次节点释放完，其他线程再竞争锁然后竞争不到再监听等待，性能是较低的。
我们可以采用临时顺序节点来实现公平锁：（每次释放完节点，通知后面一个节点即可）
一：提前创建持久化节点lock
二：请求进来，直接创建临时顺序节点。
三：判断自己是不是lock下最小的临时顺序节点，如果是，则成功获取到锁，执行业务逻辑，然后删除掉临时顺序节点，然后自己顺序后面的一个结点会接收到通知。
				         不是，则对顺序在自己前面的最近节点进行监听，前面的节点删除后会通知自己。
